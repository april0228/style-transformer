{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\n2022/05/13\nimage style transformer\n\"\"\"\nimport matplotlib.pyplot as plt # plt 用于显示图片\nimport matplotlib.image as mpimg # mpimg 用于读取图片\nfrom matplotlib.pyplot import MultipleLocator\nfrom PIL import Image\nimport numpy as nn\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport numpy as np\nimport cv2\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-17T10:59:26.824861Z","iopub.execute_input":"2022-05-17T10:59:26.825112Z","iopub.status.idle":"2022-05-17T10:59:26.830669Z","shell.execute_reply.started":"2022-05-17T10:59:26.825081Z","shell.execute_reply":"2022-05-17T10:59:26.829683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n迁移学习后修改的VGG\n  只保留特征提取层并固定参数\n  提取固定靠后几层的特征作为内容输出\n  提取固定靠前几层的特征以为风格输出\n  将最大池化改为平均池化\n\n\"\"\"\nclass transformer(nn.Module) :\n  def __init__(self,subnet) :\n    super(transformer,self).__init__()\n    self.net = subnet\n    for name,layer in self.net.named_children() :\n      if isinstance(layer,nn.MaxPool2d) :\n        self.net[int(name)] = nn.AvgPool2d(kernel_size = 2, stride = 2)\n\n\n  def get_gram_matrix(self,style) :\n    gram_matrix = []\n    for i in range(len(style)) :\n      c,h,w = style[i].size()\n      temp = style[i].view(c,h*w)\n      gram_i = torch.mm(temp,temp.t()).div(c*h*w)\n      gram_matrix.append(gram_i)\n\n    return gram_matrix\n\n  \n  def forward(self,x,content_list,style_list) :\n    content = []\n    style  = []\n    for name,layer in self.net.named_children() :\n      x = layer(x)\n      if int(name) in content_list :\n        content.append(x)\n      if int(name) in style_list :\n        style.append(x)\n\n    style_matrix = self.get_gram_matrix(style)\n\n    return content,style_matrix\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-17T10:59:26.832147Z","iopub.execute_input":"2022-05-17T10:59:26.832714Z","iopub.status.idle":"2022-05-17T10:59:26.845819Z","shell.execute_reply.started":"2022-05-17T10:59:26.832671Z","shell.execute_reply":"2022-05-17T10:59:26.845133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef train(x,net,parameter_list,content,style) :\n\n  \n\n  epoches = parameter_list[\"epoches\"]\n  k    = parameter_list[\"k\"]\n  lrate   =  parameter_list[\"lr\"]\n  device =  parameter_list[\"device\"] \n  content_list = parameter_list[\"content_list\"] \n  style_list = parameter_list[\"style_list\"] \n  path    = parameter_list[\"path\"] \n\n  \n\n  x.requires_grad = True\n  x.to(device)\n  net.to(device)\n \n  net.eval()\n  optimizer = torch.optim.Adam( [x], lr = lrate, betas = (0.9,0.999), eps = 1e-8)\n\n  content_loss_list = []\n  style_loss_list  = []\n  loss_list     = []\n  x_list = []\n  for epoch in range(epoches) :\n    \n    net.eval()\n    x = x.to(device)\n    x.requires_grad=True\n    optimizer.zero_grad()\n    content_loss = torch.tensor([0]).cuda().float()\n    style_loss  = torch.tensor([0]).cuda().float()\n    loss    = torch.tensor([0]).cuda().float()\n\n    x_content,x_style = net(x, content_list,style_list)\n\n    for i in range(len(x_content)) :\n      content_loss += F.mse_loss(x_content[i], content[i])\n    for i in range(len(x_style)) :\n      style_loss += F.mse_loss(x_style[i], style[i])\n    \n    tv_loss =  (torch.sum(torch.abs(x[:, :, :-1] - x[ :, :, 1:])) +\n                torch.sum(torch.abs(x[ :, :-1, :] - x[ :, 1:, :])))/(3*512*512)\n    loss = 1e-2*content_loss + 1e7* style_loss + 1e-3*tv_loss\n\n    content_loss_list.append(content_loss.item())\n    style_loss_list.append(style_loss.item())\n    loss_list.append(loss.item())\n    x_list.append(epoch)\n    \n    loss.backward()\n    optimizer.step()\n\n   \n    \n    if epoch % 200 == 0:\n      img = x.clone()\n      img = torch.clamp(img,0,1)*255\n      img = img.permute(1,2,0)\n      img = img.data.cpu().numpy().astype(int)\n\n      plt.imshow(img[:,:,[2,1,0]]) # 显示图片\n      plt.axis('off') # 不显示坐标轴\n      plt.show() \n      \n      print(\"epoch \",epoch ,\"\\n\",content_loss.item(),\"\\n\",style_loss.item(),\"\\n\",loss.item(),\"\\n----------------------\")\n  \n  l1=plt.plot(x_list,content_loss_list,'r--',label='content_loss')\n  l2=plt.plot(x_list,style_loss_list,'g--',label='style_loss')\n  l3=plt.plot(x_list,loss_list,'b--',label='loss')\n  plt.title('loss Conditions')\n  plt.xlabel('epoch')\n  plt.ylabel('cost')\n  #plt.legend()\n  plt.show()\n\n  return 0\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-17T10:59:28.080579Z","iopub.execute_input":"2022-05-17T10:59:28.080854Z","iopub.status.idle":"2022-05-17T10:59:28.101006Z","shell.execute_reply.started":"2022-05-17T10:59:28.080823Z","shell.execute_reply":"2022-05-17T10:59:28.10015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main() :\n\n  content_path = \"../input/dataset0/hchh.jpg\"\n  style_path = \"../input/dataset0/bt1.jpg\"\n  path = \"/kaggle/working/\"\n  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n  print(\"device = \",device)\n\n  content_img =  (cv2.imread(content_path))\n  style_img   = cv2.resize( (cv2.imread(style_path)),(content_img.shape[0],content_img.shape[1]) )\n  \n  content_tensor = torch.from_numpy(content_img).to(device).float() / 255\n  content_tensor = content_tensor.permute(2,0,1)\n                                         \n  style_tensor = torch.from_numpy(style_img).to(device).float() / 255\n  style_tensor = style_tensor.permute(2,0,1)\n  \n\n  x_tensor =  content_tensor.clone()\n  x_tensor=Variable(x_tensor,requires_grad=True)\n  \n    \n  content_list = [25]\n  style_list  = [0, 5, 10, 19, 28]\n  \n  \n  \n  net = models.vgg19(pretrained=True).features\n  net.to(device)\n  for params in net.parameters():\n    params.requires_grad = False\n  net.eval()\n  \n  \n  net1 = transformer(net)\n  content,noused = net1(content_tensor,content_list,style_list)\n  net2 = transformer(net)\n  noused,style = net2(style_tensor,content_list,style_list)\n  \n  \n\n  net3 = transformer(net)\n  parameter_list = {\n      \"device\" : device,\n      \"k\" : 0.0001,\n      \"epoches\" : 2001,\n      \"style_list\" : style_list,\n      \"content_list\" : content_list,\n      \"lr\" : 1e-2,\n      \"path\" : path\n\n  }\n  result = train(x_tensor,net3,parameter_list,content,style)\n  \n  \n  \n  \n  return 0\n\nmain()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T10:59:28.103112Z","iopub.execute_input":"2022-05-17T10:59:28.103686Z"},"trusted":true},"execution_count":null,"outputs":[]}]}